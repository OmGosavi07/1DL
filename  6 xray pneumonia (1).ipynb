{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-kMCcu1nwkBf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Import basic libraries \n",
        "\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt # visualization\n",
        "import numpy as np #handing arrays\n",
        "import pandas as pd #handling data\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Directories for train, test & Validation Set\n",
        "train_path = 'chest_xray/train'\n",
        "test_path = 'chest_xray/test'\n",
        "valid_path = 'chest_xray/val'\n",
        "\n",
        "#batch size refers to the number of training samples used in each iteration \n",
        "batch_size = 16\n",
        "\n",
        "#define image size = width x height\n",
        "img_width = 500\n",
        "img_height = 500\n",
        "\n",
        "#size 500 chosen with batch size 16 to ensure that the RAM does not crash from overuse. A low dimension size with ...\n",
        "# higher batch size is a better choice"
      ],
      "metadata": {
        "id": "T097TFIZxQW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move to where your x-ray images is located\n",
        "os.chdir(r'C:\\Users\\azizu\\Desktop\\CNN\\chest_xray\\CNN_chest_xray\\chest_xray')"
      ],
      "metadata": {
        "id": "A1hSjUJQxf0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "The dataset contained x-ray images a varying size and shape. In order to properly pass these images through the CNN\n",
        "they must be standardized to one size/shape. For this we resize the image to 500x500. The larger the image, the more\n",
        "time it takes to process. \n",
        "\"\"\"\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "#resize all images to a standard 500 x 500\n",
        "def resize_images (image_path,resize_height,resize_width):\n",
        "    if not os.path.exists(image_path):\n",
        "        os.makedirs(image_path)\n",
        "    # loop over existing images and resize\n",
        "    # change path to your path\n",
        "    for filename in glob.glob(image_path + '/*.jpeg'): #path of raw images\n",
        "        img = Image.open(filename).resize((resize_height,resize_width))\n",
        "        # save resized images to new folder with existing filename\n",
        "        img.save('{}{}{}'.format(image_path,'/',os.path.split(filename)[1]))\n",
        "    print(\"Images have been Resized!\")"
      ],
      "metadata": {
        "id": "7XDJ6eM5xjRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training images \n",
        "resize_images(train_path + '/NORMAL',img_width,img_height)\n",
        "resize_images(train_path + '/PNEUMONIA',img_width,img_height)\n",
        "#Testing images\n",
        "resize_images(test_path + '/NORMAL',img_width,img_height)\n",
        "resize_images(test_path + '/PNEUMONIA',img_width,img_height)\n",
        "#Validation images\n",
        "resize_images(valid_path + '/NORMAL',img_width,img_height)\n",
        "resize_images(valid_path + '/PNEUMONIA',img_width,img_height)"
      ],
      "metadata": {
        "id": "C79Yp6qVxn8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The downloaded dataset contained a higher number of pneumonia chest-xrays than the normal ones. In order to mitigate\n",
        "any bias in the classification, there needs to be an equal number of normal and pneumonia x-rays.\n",
        "This is performed through data augmentation where the existing images chest x-rays are artifically modified and are \n",
        "created as new images. This additionally serves as adding variability to the dataset and improving the ability\n",
        "of the model to predict new images. \n",
        "\n",
        "We will create a dataset that has a total of 10,000 images which will be split training-test-valid as 80-10-10 \n",
        "respectively.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import tf.keras.applications.vgg16.preprocess_input #error will show but it works"
      ],
      "metadata": {
        "id": "af25eiJ8xrGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
        "                                 rescale = 1./255,\n",
        "                                 shear_range = 0.2,\n",
        "                                 zoom_range = 0.2,\n",
        "                                 horizontal_flip = True) \n",
        "\n",
        "test_batch = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
        "                                   rescale = 1./255)\n",
        "\n",
        "valid_batch = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
        "                                   rescale = 1./255)"
      ],
      "metadata": {
        "id": "nYW8CBJQxuzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_images(augmented_image_path,data_batch,augmented_img_count,save_dir):\n",
        "    \n",
        "    \"\"\"\n",
        "    Create new images based on the image provided and apply transformations on them as specified in the\n",
        "    ImageDataGenerator object. These images are used to grow your training, test and/or validation set.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    image_path: Path to where the folders containing the images\n",
        "    \n",
        "    augmented_image_path: A selected image to be processed through the ImageDataGenerator. Requires an absolute\n",
        "                          path to and including the image. Example: 'train/NORMAL/IM-0115-0001.jpeg'\n",
        "    \n",
        "    save_dir: Directory where the new images should be stored.\n",
        "              \n",
        "    data_batch: ImageDataGenerator object containing the arguments for transformations to be made on the image\n",
        "    \n",
        "    augmented_img_count: Number of images to be created based on user's discretion\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt # visualization\n",
        "\n",
        "    img = load_img(augmented_image_path)  \n",
        "    x = img_to_array(img)  \n",
        "    x = x.reshape((1,) + x.shape)  \n",
        "    i = 0\n",
        "    for batch in data_batch.flow(x, batch_size=batch_size,\n",
        "                              save_to_dir=save_dir,save_format='jpeg'):\n",
        "        i += 1\n",
        "        if i > augmented_img_count:\n",
        "            break  # otherwise the generator would loop indefinitely\n",
        "\n",
        "    print('Augmentation Complete!')"
      ],
      "metadata": {
        "id": "waSVrqeXxyF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_normal = 'train/NORMAL'\n",
        "train_path_pneumonia = 'train/PNEUMONIA'\n",
        "\n",
        "test_path_normal = 'test/NORMAL'\n",
        "test_path_pneumonia = 'test/PNEUMONIA'\n",
        "\n",
        "valid_path_normal = 'val/NORMAL'\n",
        "valid_path_pneumonia = 'val/PNEUMONIA'"
      ],
      "metadata": {
        "id": "UuioUtovxy8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training images are augmented and placed into respective directories. Images previously found in the directory\n",
        "#are used for augmentation. \n",
        "#The training directory should contain a total of 8000 images where 4000 is NORMAL and 4000 is PNEUMONIA\n",
        "\n",
        "augment_images('train/NORMAL/IM-0117-0001.jpeg',train_batch,3100,'train/NORMAL')\n",
        "augment_images('train/PNEUMONIA/person1_bacteria_1.jpeg',train_batch,3200,'train/PNEUMONIA')"
      ],
      "metadata": {
        "id": "3vVS_ff8x15X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing images are augmented and placed into respective directories. Images previously found in the directory\n",
        "#are used for augmentation. \n",
        "#The testing directory should contain a total of 1000 images where 500 is NORMAL and 500 is PNEUMONIA\n",
        "\n",
        "augment_images('test/NORMAL/IM-0006-0001.jpeg',test_batch,250,'test/NORMAL')\n",
        "augment_images('test/PNEUMONIA/person1_virus_6.jpeg',test_batch,300,'test/PNEUMONIA')"
      ],
      "metadata": {
        "id": "YaN7mzSmx7tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#valid images are augmented and placed into respective directories. Images previously found in the directory\n",
        "#are used for augmentation. \n",
        "#The valid directory should contain a total of 1000 images where 500 is NORMAL and 500 is PNEUMONIA\n",
        "\n",
        "augment_images('val/NORMAL/NORMAL2-IM-1427-0001.jpeg',valid_batch,230,'val/NORMAL')\n",
        "augment_images('val/PNEUMONIA/person1946_bacteria_4874.jpeg',valid_batch,200,'val/PNEUMONIA')"
      ],
      "metadata": {
        "id": "G_3Uj6OCx9Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_batch.flow_from_directory(directory = r'C:\\Users\\azizu\\Desktop\\CNN\\chest_xray\\CNN_chest_xray\\chest_xray\\train', \n",
        "                     target_size = (img_width,img_height), \n",
        "                     classes = ['NORMAL','PNEUMONIA'], \n",
        "                     batch_size = batch_size)"
      ],
      "metadata": {
        "id": "nXd4jMkoyCi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_batch.flow_from_directory(directory = 'train', \n",
        "                     target_size = (img_width,img_height), \n",
        "                     classes = ['NORMAL','PNEUMONIA'], \n",
        "                     batch_size = batch_size)\n",
        "\n",
        "\n",
        "#test images dont need to be modified only rescaled to fit the sizes of all the training images\n",
        "test = test_batch.flow_from_directory(directory = 'test', \n",
        "                     target_size = (img_width,img_height), \n",
        "                     shuffle=False,\n",
        "                     classes = ['NORMAL','PNEUMONIA'], \n",
        "                     batch_size = batch_size)\n",
        "\n",
        "valid = valid_batch.flow_from_directory(directory = 'val', \n",
        "                     target_size = (img_width,img_height), \n",
        "                     classes = ['NORMAL','PNEUMONIA'], \n",
        "                     batch_size = batch_size)"
      ],
      "metadata": {
        "id": "-GojwWPdyHx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Visualize the data augmented images from the training dataset\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train_img, train_labels = next(train)\n",
        "test_img, test_labels = next(test)\n",
        "valid_img, valid_labels = next (valid)\n",
        "\n",
        "#plot the images from the datasets\n",
        "def plotImages(images_arr,labels,filename):\n",
        "    fig, axes = plt.subplots(4,4,figsize = (12,12))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax, lab in zip(images_arr, axes,labels):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        dic = {0:'NORMAL',1:'PNEUMONIA'}\n",
        "        ax.set_title(dic.get(lab[0]))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig(filename + '.png')"
      ],
      "metadata": {
        "id": "9cKHSEe-yIc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Visualization of the training data images that have been pre-processed by the ImageDataGenerator\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "plotImages(train_img,train_labels,'train_images')"
      ],
      "metadata": {
        "id": "F2Z3RvLZyMze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Visualization of the testing data images that have been pre-processed by the ImageDataGenerator\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "plotImages(test_img,test_labels,'test_images')"
      ],
      "metadata": {
        "id": "NSqQwK6JyPgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Visualization of the validation data images that have been pre-processed by the ImageDataGenerator\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "plotImages(valid_img,valid_labels,'valid_images')"
      ],
      "metadata": {
        "id": "Bupm_PK8ySyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Import necessary CNN libraries \n",
        "\n",
        "\"\"\"\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "_T3KS9zlyVeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Building the CNN architecture\n",
        "\n",
        "\"\"\"\n",
        "num_classes = 2\n",
        "epochs = 10\n",
        "\n",
        "cnn = Sequential()\n",
        "\n",
        "cnn.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (img_width,img_height,3)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "cnn.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (img_width,img_height,3)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "cnn.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (img_width,img_height,3)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "cnn.add(Conv2D(64,(3,3),activation = 'relu',input_shape = (img_width,img_height,3)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "cnn.add(Conv2D(64,(3,3),activation = 'relu',input_shape = (img_width,img_height,3)))\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(Dense(activation = 'relu',units = 128))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(activation = 'relu',units = 64))\n",
        "cnn.add(Dense(num_classes,activation = 'softmax'))\n",
        "\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "2EVAlAjayYq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Flow diagram of the CNN architecture. The '?' represents the varying batch sizes.\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import os\n",
        "\n",
        "os.environ['PATH'] = os.environ['PATH']+';'+os.environ['CONDA_PREFIX']+r\"\\Library\\bin\\graphviz\"\n",
        "\n",
        "plot_model(cnn,to_file = 'cnn_architecture.png',show_shapes = True, show_layer_names = True, rankdir = 'TB',expand_nested = True)\n",
        "#rankdir = tb --> vertical, LR --> horizontal"
      ],
      "metadata": {
        "id": "yvc9Y5-aybXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create necessary parameters prior to training the data. \n",
        "\n",
        "EarlyStopping is used to stop the training based on \n",
        "some metric and conditions. This will help avoid overfitting the model. In this case, early monitors the validation \n",
        "loss and ensures that it is at a minimum, if the loss increases beyond 3 epochs (patience), the training will end.\n",
        "\n",
        "Learning rate is reduced when the model has stopped improving. \n",
        "\n",
        "class_weights are computed to ensure the emphasis on weights are distributed equally on the ANN\n",
        "\"\"\"\n",
        "\n",
        "early = EarlyStopping(monitor = 'val_loss',mode = 'min',patience = 3)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss',patience = 2, verbose = 1,\n",
        "                                            factor = 0.3, min_lr = 0.000001)\n",
        "\n",
        "callbacks_list = [early,learning_rate_reduction]\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "weights = compute_class_weight('balanced',np.unique(train.classes),\n",
        "                               train.classes)\n",
        "\n",
        "cw = dict(zip(np.unique(train.classes),weights))\n",
        "print(cw)"
      ],
      "metadata": {
        "id": "LBlUueBvyecx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The model will now be trained on the 'train' data made earlier. \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cnn.fit(train,epochs = 10, validation_data = valid, class_weight = cw,\n",
        "        callbacks = callbacks_list, verbose = 1)"
      ],
      "metadata": {
        "id": "iSZuxBu4yfMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model to disk\n",
        "cnn.save('cnn.h5')\n",
        "print('saved to disk')"
      ],
      "metadata": {
        "id": "hzNq4YWLyjY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import load_model \n",
        "# load model\n",
        "model = tf.keras.models.load_model('cnn.h5')"
      ],
      "metadata": {
        "id": "pgWtm0VoynTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Plot training and validation losses over epoch. \n",
        "\"\"\"\n",
        "loss_train = cnn.history.history['loss']\n",
        "loss_val = cnn.history.history['val_loss']\n",
        "epochs = range(1,5)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efDKt159yqZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Plot training and validation accuracy over epoch. \n",
        "\"\"\"\n",
        "acc_train = cnn.history.history['accuracy']\n",
        "acc_val = cnn.history.history['val_accuracy']\n",
        "epochs = range(1,5)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C-aTQIriyq48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy metric on test data\n",
        "score = cnn.evaluate(test)\n",
        "print('The testing accuracy is : ', score[1]*100,'%')"
      ],
      "metadata": {
        "id": "S62q0yOwyuzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Make a prediction on the test set.\n",
        "\"\"\"\n",
        "\n",
        "preds = cnn.predict(test,verbose = 1)\n",
        "predictions = preds.copy()\n",
        "predictions[predictions <= 0.5] = 0\n",
        "predictions[predictions > 0.5] = 1"
      ],
      "metadata": {
        "id": "ApSfa2aQyxzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Function to plot a confusion matrix to assess classifier performance using predicted and true labels.\n",
        "\"\"\"\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "       \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "    \n",
        "    SMALL_SIZE = 15\n",
        "    MEDIUM_SIZE = 16\n",
        "    BIGGER_SIZE = 18\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cm, interpolation='none', cmap=cmap,aspect = 'equal')\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n",
        "    plt.xlim(-0.5, 1.5)\n",
        "    plt.ylim(-0.5, 1.5)\n",
        "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
        "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "    #plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AzPsx56By0kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Non-Normalized Confusion matrix on Test dataset\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "y_true = test.classes\n",
        "cm = confusion_matrix(y_pred,y_true)\n",
        "plot_confusion_matrix(cm,['NORMAL','PNEUMONIA'],'Test Data Confusion Matrix', normalize=False)"
      ],
      "metadata": {
        "id": "4NoMYLnmzMPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Normalized Confusion matrix on Test dataset\n",
        "\"\"\"\n",
        "\n",
        "plot_confusion_matrix(cm,['NORMAL','PNEUMONIA'],'Test Data Confusion Matrix', normalize=True)"
      ],
      "metadata": {
        "id": "i2ryYpr4zO9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Display performance metrics of the CNN\n",
        "\"\"\"\n",
        "print(classification_report(y_true,y_pred,target_names =['NORMAL','PNEUMONIA']))"
      ],
      "metadata": {
        "id": "ZldheCqqzVuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}